---
title: null
description: null
date: null
tags:
  - insight
redirect:
  - /4yB2pw
---

Human beings aren't clockwork machines. We might like to pretend that they are—it fits our mental model of a rational, orderly universe—but behaviour is not reducible to a machine-like system of inputs and outputs. Nevertheless, a common understanding of human cognition assumes just this, informed by an operational metaphor that borrows from computation.

In fact, there's good evidence that human beings are not rational actors at all. When we try to treat behaviour this way, we [[Quant data is lossy | lose a great deal of information]] and also limit our ability to design more elegant, effective solutions. We sacrifice deep understanding of the contexts that inform behaviour. This leaves us less equipped to process and learn from qualitative data that can't easily be reduced down to numbers.

---

#### Related:

- [[Objectivism assumes a concrete, knowable world]]
- [[Quantitative analysis is not inherently more reliable than qualitative data]]
- [[Qualitative and quantitative research represent different philosophies of knowledge]]
- [[Qualitative research creates mental models about the problem space]]
- [[Quant data is lossy]]

#### Reference

[[≈ Sensemaking | Madsbjerg, Christian. Sensemaking: The Power of the Humanities in the Age of the Algorithm. Hachette Books, 2017.]]

[Sutherland, Rory. Alchemy: The Dark Art and Curious Science of Creating Magic in Brands, Business, and Life. Illustrated edition. William Morrow, 2019.](https://publish.obsidian.md/mobydiction/Sutherland+-+Alchemy)
